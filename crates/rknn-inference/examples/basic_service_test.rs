use rknn_inference::{get_class_name, ImageBuffer, ImageFormat, InferenceService};
use std::sync::Arc;
use std::time::{Duration, Instant};

fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘        YOLOv8 RKNN æ¨ç†æœåŠ¡åŸºç¡€æµ‹è¯•             â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let model_path = "models/yolov8m.rknn";
    let test_image_path = "tests/test.jpg";
    let num_workers = 3;
    let max_queue_size = 3;

    println!("æµ‹è¯•é…ç½®:");
    println!("  æ¨¡å‹è·¯å¾„:     {}", model_path);
    println!("  æµ‹è¯•å›¾ç‰‡:     {}", test_image_path);
    println!("  å·¥ä½œçº¿ç¨‹æ•°:   {}", num_workers);
    println!("  æœ€å¤§é˜Ÿåˆ—å¤§å°: {}", max_queue_size);
    println!("  è¯´æ˜:         3çº¿ç¨‹é¿å…CPUæ»¡è½½");
    println!();

    // 1. åŠ è½½æµ‹è¯•å›¾ç‰‡
    println!("ğŸ“· åŠ è½½æµ‹è¯•å›¾ç‰‡...");
    let img = image::open(test_image_path).expect("Failed to load test image");
    let img = img.to_rgb8();
    println!("âœ“ å›¾ç‰‡åŠ è½½æˆåŠŸ: {}x{}", img.width(), img.height());
    println!();

    // 2. åˆ›å»ºæ¨ç†æœåŠ¡
    println!("ğŸš€ åˆ›å»ºæ¨ç†æœåŠ¡...");
    let service = Arc::new(InferenceService::new(model_path, num_workers, max_queue_size)
        .expect("Failed to create inference service"));
    println!("âœ“ æ¨ç†æœåŠ¡åˆ›å»ºæˆåŠŸ");
    println!();

    // 3. æµ‹è¯• 1: å•ä¸ªæ¨ç†ä»»åŠ¡
    println!("ğŸ§ª æµ‹è¯• 1: å•ä¸ªæ¨ç†ä»»åŠ¡");
    test_single_inference(&service, &img);

    // 4. æµ‹è¯• 2: é¡ºåºæ¨ç†ä»»åŠ¡
    println!("ğŸ§ª æµ‹è¯• 2: é¡ºåºæ¨ç†ä»»åŠ¡ï¼ˆ10ä¸ªä»»åŠ¡ï¼‰");
    test_sequential_inference(&service, &img, 10);

    // 5. æµ‹è¯• 3: å¹¶å‘æ¨ç†ä»»åŠ¡
    println!("ğŸ§ª æµ‹è¯• 3: å¹¶å‘æ¨ç†ä»»åŠ¡ï¼ˆ3ä¸ªä»»åŠ¡ï¼‰");
    test_concurrent_inference(&service, &img, 3);

    // 6. æµ‹è¯• 4: é˜Ÿåˆ—æ»¡æµ‹è¯•
    println!("ğŸ§ª æµ‹è¯• 4: é˜Ÿåˆ—æ»¡æµ‹è¯•ï¼ˆå¿«é€Ÿæäº¤8ä¸ªä»»åŠ¡ï¼‰");
    test_queue_overflow(&service, &img, 8);

    // 7. æœ€ç»ˆç»Ÿè®¡
    println!("ğŸ“Š æœ€ç»ˆç»Ÿè®¡:");
    let stats = service.get_stats();
    println!("  å¤„ç†çš„ä»»åŠ¡æ•°: {}", stats.processed_tasks);
    println!("  ä¸¢å¼ƒçš„ä»»åŠ¡æ•°: {}", stats.dropped_tasks);
    println!("  é˜Ÿåˆ—ä¸­å‰©ä½™:   {}", stats.queue_size);
    println!("  ä¸‹ä¸€ä¸ªæœŸæœ›ID: {}", stats.next_expected_task_id);
    println!();

    println!("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼");
}

fn test_single_inference(service: &Arc<InferenceService>, img: &image::RgbImage) {
    println!("  è¿è¡Œå•ä¸ªæ¨ç†ä»»åŠ¡...");

    let image_buffer = ImageBuffer {
        width: img.width() as i32,
        height: img.height() as i32,
        format: ImageFormat::Rgb888,
        data: img.clone().into_raw(),
    };

    let start = Instant::now();
    let result = service.inference_sync(image_buffer, Duration::from_secs(5));
    let elapsed = start.elapsed();

    match result {
        Ok(detections) => {
            println!("    âœ“ æ¨ç†æˆåŠŸ: {:.2}ms, æ£€æµ‹åˆ° {} ä¸ªå¯¹è±¡", elapsed.as_millis(), detections.len());
            for (i, det) in detections.iter().take(3).enumerate() {
                println!("      å¯¹è±¡ {}: ç½®ä¿¡åº¦ {:.2}%, ç±»åˆ« {}",
                         i + 1,
                         det.confidence * 100.0,
                         get_class_name(det.class_id).unwrap_or("unknown".to_string()));
            }
        }
        Err(e) => {
            println!("    âœ— æ¨ç†å¤±è´¥: {:?}", e);
        }
    }
    println!();
}

fn test_sequential_inference(service: &Arc<InferenceService>, img: &image::RgbImage, num_tasks: usize) {
    println!("  è¿è¡Œ {} ä¸ªé¡ºåºæ¨ç†ä»»åŠ¡...", num_tasks);

    let start_total = Instant::now();
    let mut inference_times = Vec::new();
    let mut success_count = 0;
    let mut total_detections = 0;

    for i in 0..num_tasks {
        let image_buffer = ImageBuffer {
            width: img.width() as i32,
            height: img.height() as i32,
            format: ImageFormat::Rgb888,
            data: img.clone().into_raw(),
        };

        let start = Instant::now();
        let result = service.inference_sync(image_buffer, Duration::from_secs(10));
        let elapsed = start.elapsed();

        match result {
            Ok(detections) => {
                inference_times.push(elapsed.as_millis());
                success_count += 1;
                total_detections += detections.len();
                println!("    ä»»åŠ¡ {}: {:.2}ms, {} ä¸ªå¯¹è±¡", i + 1, elapsed.as_millis(), detections.len());
            }
            Err(e) => {
                println!("    ä»»åŠ¡ {}: å¤±è´¥ ({:?})", i + 1, e);
            }
        }
    }

    let total_time = start_total.elapsed();

    println!("  é¡ºåºæµ‹è¯•ç»“æœ:");
    println!("    æ€»è€—æ—¶: {:.2}ms", total_time.as_millis());
    println!("    æˆåŠŸç‡: {}/{} ({:.1}%)", success_count, num_tasks, success_count as f64 / num_tasks as f64 * 100.0);
    println!("    æ€»æ£€æµ‹å¯¹è±¡: {}", total_detections);

    if !inference_times.is_empty() {
        let min_time = inference_times.iter().min().unwrap();
        let max_time = inference_times.iter().max().unwrap();
        let avg_time = inference_times.iter().sum::<u128>() as f64 / inference_times.len() as f64;
        println!("    æ¨ç†æ—¶é—´ç»Ÿè®¡:");
        println!("      æœ€å°: {:.2}ms", min_time);
        println!("      æœ€å¤§: {:.2}ms", max_time);
        println!("      å¹³å‡: {:.2}ms", avg_time);
        println!("      ååé‡: {:.2} FPS", 1000.0 / avg_time);
    }
    println!();
}

fn test_concurrent_inference(service: &Arc<InferenceService>, img: &image::RgbImage, num_tasks: usize) {
    println!("  è¿è¡Œ {} ä¸ªå¹¶å‘ä»»åŠ¡...", num_tasks);

    let start_total = Instant::now();
    let mut handles = Vec::new();

    // åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡
    for i in 0..num_tasks {
        let image_buffer = ImageBuffer {
            width: img.width() as i32,
            height: img.height() as i32,
            format: ImageFormat::Rgb888,
            data: img.clone().into_raw(),
        };

        let service_clone = service.clone();
        let handle = std::thread::spawn(move || {
            let start = Instant::now();
            let result = service_clone.inference_sync(image_buffer, Duration::from_secs(15));
            let elapsed = start.elapsed();
            (i, result, elapsed)
        });

        handles.push(handle);
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let mut completed_tasks = 0;
    let mut total_detections = 0;
    let mut inference_times = Vec::new();
    let mut success_count = 0;

    for handle in handles {
        match handle.join() {
            Ok((task_id, result, elapsed)) => {
                completed_tasks += 1;
                let elapsed_ms = elapsed.as_millis();

                match result {
                    Ok(detections) => {
                        inference_times.push(elapsed_ms);
                        success_count += 1;
                        total_detections += detections.len();
                        println!("    ä»»åŠ¡ {}: {:.2}ms, {} ä¸ªå¯¹è±¡", task_id + 1, elapsed_ms, detections.len());
                    }
                    Err(e) => {
                        println!("    ä»»åŠ¡ {}: å¤±è´¥ ({:?})", task_id + 1, e);
                    }
                }
            }
            Err(e) => {
                println!("    çº¿ç¨‹é”™è¯¯: {:?}", e);
            }
        }
    }

    let total_elapsed = start_total.elapsed();

    println!("  å¹¶å‘æµ‹è¯•ç»“æœ:");
    println!("    å®Œæˆä»»åŠ¡æ•°: {}", completed_tasks);
    println!("    æˆåŠŸä»»åŠ¡æ•°: {}", success_count);
    println!("    æ€»æ£€æµ‹å¯¹è±¡: {}", total_detections);
    println!("    æ€»è€—æ—¶: {:.2}ms", total_elapsed.as_millis());

    if !inference_times.is_empty() {
        let min_time = inference_times.iter().min().unwrap();
        let max_time = inference_times.iter().max().unwrap();
        let avg_time = inference_times.iter().sum::<u128>() as f64 / inference_times.len() as f64;

        println!("    æ¨ç†æ—¶é—´ç»Ÿè®¡:");
        println!("      æœ€å°: {:.2}ms", min_time);
        println!("      æœ€å¤§: {:.2}ms", max_time);
        println!("      å¹³å‡: {:.2}ms", avg_time);

        let theoretical_time = avg_time * num_tasks as f64;
        let efficiency = theoretical_time / total_elapsed.as_millis() as f64;
        println!("    å¹¶å‘æ•ˆç‡:");
        println!("      ç†è®ºæ€»æ—¶é—´: {:.2}ms", theoretical_time);
        println!("      å®é™…æ€»æ—¶é—´: {:.2}ms", total_elapsed.as_millis());
        println!("      å¹¶å‘å€æ•°:   {:.2}x", efficiency);
        println!("      CPU åˆ©ç”¨ç‡:  {:.1}%", efficiency / num_tasks as f64 * 100.0);
    }
    println!();
}

fn test_queue_overflow(service: &Arc<InferenceService>, img: &image::RgbImage, num_tasks: usize) {
    println!("  å¿«é€Ÿæäº¤ {} ä¸ªä»»åŠ¡ï¼ˆé˜Ÿåˆ—å¤§å°ä¸º3ï¼‰...", num_tasks);

    let start_total = Instant::now();
    let mut handles = Vec::new();

    // å¿«é€Ÿæäº¤å¤§é‡ä»»åŠ¡
    for i in 0..num_tasks {
        let image_buffer = ImageBuffer {
            width: img.width() as i32,
            height: img.height() as i32,
            format: ImageFormat::Rgb888,
            data: img.clone().into_raw(),
        };

        let service_clone = service.clone();
        let handle = std::thread::spawn(move || {
            let start = Instant::now();
            let result = service_clone.inference_sync(image_buffer, Duration::from_secs(20));
            let elapsed = start.elapsed();
            (i, result, elapsed)
        });

        handles.push(handle);

        // ç«‹å³æäº¤ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼Œæ¨¡æ‹Ÿå¿«é€Ÿè¯·æ±‚
        if i < num_tasks - 1 {
            std::thread::sleep(Duration::from_millis(1));
        }
    }

    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    let mut completed_tasks = 0;
    let mut dropped_tasks = 0;
    let mut total_detections = 0;

    for handle in handles {
        match handle.join() {
            Ok((task_id, result, elapsed)) => {
                completed_tasks += 1;

                match result {
                    Ok(detections) => {
                        total_detections += detections.len();
                        println!("    ä»»åŠ¡ {}: {:.2}ms, {} ä¸ªå¯¹è±¡", task_id + 1, elapsed.as_millis(), detections.len());
                    }
                    Err(e) => {
                        if format!("{:?}", e).contains("Timeout") {
                            dropped_tasks += 1;
                            println!("    ä»»åŠ¡ {}: è¶…æ—¶ï¼ˆå¯èƒ½è¢«ä¸¢å¼ƒï¼‰", task_id + 1);
                        } else {
                            println!("    ä»»åŠ¡ {}: å¤±è´¥ ({:?})", task_id + 1, e);
                        }
                    }
                }
            }
            Err(e) => {
                println!("    çº¿ç¨‹é”™è¯¯: {:?}", e);
            }
        }
    }

    let total_elapsed = start_total.elapsed();

    println!("  é˜Ÿåˆ—æº¢å‡ºæµ‹è¯•ç»“æœ:");
    println!("    æäº¤ä»»åŠ¡æ•°: {}", num_tasks);
    println!("    å®Œæˆä»»åŠ¡æ•°: {}", completed_tasks);
    println!("    æˆåŠŸä»»åŠ¡æ•°: {}", completed_tasks - dropped_tasks);
    println!("    ä¸¢å¼ƒ/è¶…æ—¶æ•°: {}", dropped_tasks);
    println!("    æ€»æ£€æµ‹å¯¹è±¡: {}", total_detections);
    println!("    æ€»è€—æ—¶: {:.2}ms", total_elapsed.as_millis());

    // æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
    let stats = service.get_stats();
    println!("    æœåŠ¡ç»Ÿè®¡:");
    println!("      é˜Ÿåˆ—ä¸¢å¼ƒæ•°: {}", stats.dropped_tasks);
    println!("      å·²å¤„ç†æ•°:   {}", stats.processed_tasks);
    println!();
}